# MuLLM - 면접 답변 자동 생성 프로그램

## !!주의!!

현재 프로젝트는 백엔드에서 콘다 가상환경으로 들어가 모델을 구동하는 경우 정상적으로 답이 실행되지 않는 에러가 있습니다.
UTF 설정 관련으로 추정하나, 아직 그 답을 찾지 못하였습니다.
따라서, 본 프로젝트는 아직 정상적인 실행이 되지 않는 단계입니다. (모델을 따로 colab에 구동할 경우, 답변이 잘 생성되는 것을 확인할 수 있습니다.)

## 소개

**MuLLM**은 구직자들을 돕기 위해 면접 질문에 대한 예시 답변을 생성하는 프로젝트입니다. 대형 언어 모델(LLM)을 웹 인터페이스와 통합하여 사용자가 직무와 특정 면접 질문을 입력하면 일관되고 맥락에 맞는 답변을 제공합니다.

## 목차

1. [배경 및 개요](#배경-및-개요)
2. [프로젝트 구조](#프로젝트-구조)
3. [설치 및 설정](#설치-및-설정)
4. [프로젝트 실행](#프로젝트-실행)
5. [웹 인터페이스](#웹-인터페이스)
6. [API 엔드포인트](#api-엔드포인트)
7. [개선 사항](#개선-사항)
8. [기여자](#기여자)

## 배경 및 개요

구직자의 수가 853,000명을 넘어서면서 거의 모든 기업이 이력서 검토 후 면접 라운드를 진행합니다. **MuLLM**은 이러한 구직자들을 돕기 위해 면접 질문에 대한 예시 답변을 생성합니다. 이 프로젝트는 Meta에서 개발한 대형 언어 모델인 LLaMA 3을 사용하며, 상업적 용도로 무료로 사용할 수 있습니다.

### LLaMA 3 사용의 장점:
- 추가 비용 없음
- 데이터 유출 없음
- 맞춤형 학습 효과

### 데이터:
- [AI 허브 오픈 데이터](https://www.aihub.or.kr/aihubdata/data/view.do?currMenu=115&topMenu=100&aihubDataSe=data&dataSetSn=71592)
- 약 70,000개의 면접 질문-답변 쌍 (텍스트 데이터 사용)

### 모델:
- Meta의 LLaMA 3
- 자원 제약으로 인해 8B 모델 선택
- GPU A100과 32GB RAM을 사용한 Colab에서의 학습
- 총 학습 시간: 8시간 30분
---
### 모델 작동 예시

#### Llama3 8B 모델에 질문을 입력했을 때 vs MuLLM 모델에 질문을 입력했을 때

Q : 당신의 장단점을 설명해주세요.
```
Llama3 8B : 의도는 열심히 일하고 싶은데, 과로가 가끔 생기곤 합니다. 하지만 이를 보완하기 위해 주말에 운동을 하고 책을 읽는 습관을 가졌습니다.

MuLLM : 제 장점은 일찍부터 열심히 일하는 성격이고, 다른 사람의 생각과 의견을 존중하는 것이며, 새로운 경험을 통해 성장하는 능력이 있습니다. 제 단점은 때때로 과열하는 경향이 있고, 일부는 자신의 의견을 쉽게 말하는 것이 아니라, 더 생각하는 것이 있습니다.
```
#### ChatGPT에 질문을 입력했을 때 vs MuLLM 모델에 질문을 입력했을 때

Q : 당신은 IT 면접자입니다. 당신의 특기를 설명해주세요.
```
ChatGPT : 안녕하세요, 저는 [이름]입니다. IT 분야에서 제가 가진 특기를 간략하게 소개드리겠습니다. 저는 다양한 프로그래밍 언어에 능숙하며, 특히 Python, Java, 그리고 JavaScript를 주로 사용합니다.

MuLLM : 제 특기는 다양한 분야의 콘텐츠를 생성하는 것입니다. 이 특기는 저에게 새로운 경험과 도전을 주는 것은 물론, 다양한 사람들과의 교감을 통해 새로운 것을 배울 수 있는 기회를 제공합니다. 이 특기가 있기 때문에 저는 새로운 언어를 배울 수 있었고, 다양한 문화에 대한 이해를 높일 수 있었습니다.
```
#### 

제 특기는 다양한 분야의 콘텐츠를 생성하는 것입니다. 이 특기는 저에게 새로운 경험과 도전을 주는 것은
물론, 다양한 사람들과의 교감을 통해 새로운 것을 배울 수 있는 기회를 제공합니다. 이 특기가 있기 때문
에 저는 새로운 언어를 배울 수 있었고, 다양한 문화에 대한 이해를 높일 수 있었습니다.

---
## 프로젝트 구조

```plaintext
entirepjt/
├── backend/
│   ├── bin/
│   │   └── bash/
│   ├── src/
│   │   ├── main/
│   │   │   └── java/
│   │   │       └── com/
│   │   │           └── ssafy/
│   │   │               ├── controller/
│   │   │               ├── model/
│   │   │               └── service/
│   │   └── resources/
│   │       └── static/
│   │           └── css/
│   │           └── fonts/
│   │           └── js/
│   └── test/
│       └── java/
│           └── com/
│               └── ssafy/
├── frontend/
│   ├── src/
│   │   ├── assets/
│   │   │   └── fonts/
│   │   ├── components/
│   │   ├── router/
│   │   └── store/
└── ml/
    └── scripts/
        └── model.py
```

## 설치 및 설정

### 사전 요구 사항
- [Node.js](https://nodejs.org/)
- [Python](https://www.python.org/) 및 conda
- [Git](https://git-scm.com/)
- [Spring Boot](https://spring.io/projects/spring-boot)

### 설치 단계

1. **리포지토리 클론:**
   ```bash
   git clone https://github.com/InnocentNewjeans/InterviewAnswerMaker.git
   cd entirepjt
   ```

2. **백엔드 설정:**
   - 백엔드 디렉토리로 이동:
     ```bash
     cd backend
     ```
   - 필요한 종속성 설치:
     ```bash
     ./mvnw install
     ```

3. **프론트엔드 설정:**
   - 프론트엔드 디렉토리로 이동:
     ```bash
     cd ../frontend
     ```
   - 필요한 종속성 설치:
     ```bash
     npm install
     ```

4. **Python 환경 설정:**
   - ml/scripts 디렉토리로 이동:
     ```bash
     cd ../ml/scripts
     ```
   - conda 환경 생성 및 활성화:
     ```bash
     conda create --name realfinal python=3.8
     conda activate realfinal
     pip install -r requirements.txt
     ```

## 프로젝트 실행

### 백엔드 실행
1. 백엔드 디렉토리로 이동:
   ```bash
   cd backend
   ```
2. Spring Boot 애플리케이션 시작:
   ```bash
   ./mvnw spring-boot:run
   ```

### 프론트엔드 실행
1. 프론트엔드 디렉토리로 이동:
   ```bash
   cd ../frontend
   ```
2. Vue.js 애플리케이션 시작:
   ```bash
   npm run serve
   ```

##

## 웹 인터페이스

### InputPage.vue
- 사용자가 직무와 면접 질문을 입력할 수 있습니다.
- 제출 버튼을 누르면 데이터가 백엔드로 전송되고 Output 페이지로 이동합니다.

### OutputPage.vue
- 입력된 질문과 생성된 답변을 표시합니다.

## API 엔드포인트

### 질문 저장
- **URL:** `/api/questions`
- **메서드:** `POST`
- **요청 본문:** `question`과 `position`이 포함된 JSON.
- **응답:** 저장된 질문 객체.

### 답변 예측
- **URL:** `/api/predict`
- **메서드:** `POST`
- **요청 본문:** `questionId`가 포함된 JSON.
- **응답:** 없음 (답변은 데이터베이스에 저장됨).

### 질문 가져오기
- **URL:** `/api/questions/{id}`
- **메서드:** `GET`
- **응답:** 생성된 답변이 포함된 질문 객체.

## 개선 사항

- 불완전한 답변 처리
- 숫자 데이터의 이해 향상
- 개인 커버 레터를 기반으로 질문 생성
- 다중 학습 라운드
- 숫자 데이터를 위한 별도 모델 디자인
- 개인 데이터를 저장하기 위한 CRUD 작업 구현

## 기여자

- **김민혁**
- **김영찬**
